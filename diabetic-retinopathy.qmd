---
title: "Diabetic Retinopathy Detection"
author: "Deepak Jeyarajan"
format:
    html:
        toc: true
        html-math-method: katex
        css: styles.css
---

# Introduction
- In this review, we break down the exact model that Gargeya & Leng use in their paper "Automated Identification of Diabetic Retinopathy Using Deep Learning". 
- The Overview and Key Takeaways sections are written for clinicians, the Technical Overview section is written for clinicians who want more detail on the nitty gritty (and we show you how easy it is to train a model yourself!).  
- As always, it is not expected for you to know anything about Deep Learning and jargon is explained where appropriate. 

# Overview
In identifying diabetic retinopathy (DR), we traditionally interpret the retinal fundus, looking for characteristics like microaneurysms, neovascularisation and hard exudates [@eyewiki] (eyewiki.aao.org/Diabetic Retinopathy). 

## The Basic Concept
Broadly speaking, we're turning <b>data</b> (the fundal image) into <b>data</b> (a number saying if DR is present or not). The fundal image is itself made out of pixels, which are numbers. 

Here is information about 1 pixel in a zoomed in fundal picture. 
![Coordinates and RBG values](assets/rbg-channels2.png){.lightbox}

The values on the left (777 and 424) refer to the coordinates of the pixel. The values on the right refer to its "Red, Blue, Green" (RGB) values - how red, blue and green the pixel is out of a maximum of 255. Understandably, the fundus is more red than blue or green (181,95,48).

This is what it would look like if we split up the 3 colour channels. 
![alt text](assets/rbg-channels.png "Red, Green & Blue Channels")


But the main point is that an image is simply numbers!
For simplicity's sake, let's assume there is just 1 channel. 

This is the essence of the whole model.
![Our Goal Grossly Simplified](assets/DRorNot.png)


## The Basic Math
We're going to use basic addition and multiplication to turn all these pixel numbers into a final number.

The first transformation we do is called a convolution (hence these models are called convolutional neural networks).

You start off with a the image matrix and a kernal (a matrix of numbers)
![Matrix & Kernal](assets/matrix%20%26%20kernal.png)

We move a kernal along the image, multiplying each kernal's value by the pixel value and adding all of them up. This gives us a matrix of our processed data.
![Convolution](assets/convolutiongif.gif)
After we apply the kernal through the image, it gives us a new matrix that we call a feature map. 


- multiplying and adding up our data by random numbers (x) â‡’ called a convolution 
    - gif of convolutions shrinking data
    - do you see how now our matrix shrinks all the way down to 1 number
- now we have our data, our convolutions and one number at the end
    - now we know what answer we want, now we can change our random kernel numbers to what will get us our answer!
    - it's sorta like looking at the answer sheet and changing our working out to get to the final answer
    - using basic calculus, we can figure out if each random number in each kernel needs to increase or decrease to get closer to the actual answer
        - the metric we call that we optimise for is the 'loss function'

# Key Takeaways

# Technical Overview
    # Fixing our Data
    # Transforming our Data
    # Ending with Probabilities
    # Getting the Answer