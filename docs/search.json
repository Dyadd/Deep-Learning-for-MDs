[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practical Deep Learning for MDs",
    "section": "",
    "text": "What is the point of this?\nIn medicine, we collect data from patients (Hx, Ex, Ix) to make meaningful conclusions (Dx, Mx). Data analysis tools like Deep Learning have shown success (CXR, sepsis ICU?) and failure (EPIC & sepsis) in helping us derive meaningful conclusions better.\nIt’s my belief that clinicians should be equipped with the basic knowledge of how it works, its benefits and limitations, so we can safely and confidently use it in our clinical practice. This website is a resource to do just that - to bridge clinical practice and emerging tools.\nOften, clinicians encounter new papers in journals that outline groundbreaking discoveries regarding the application of deep learning in their field. However, due to the limitations of academic papers, they often fail to provide intuitive explanations of fundamental concepts such as what a neural network is. On the other hand, technical papers are far too unapproachable. In this website, I break down influential papers in each field and show you exactly what is going on behind the scenes.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "insert contact details"
  },
  {
    "objectID": "diabetic-retinopathy.html",
    "href": "diabetic-retinopathy.html",
    "title": "Diabetic Retinopathy Detection",
    "section": "",
    "text": "add technical overview: quote text from Gargeya’s study & recreate in code\nadd references/citations\nadd estimated reading time, sharing functions",
    "crumbs": [
      "Ophthalmology",
      "Diabetic Retinopathy Detection"
    ]
  },
  {
    "objectID": "diabetic-retinopathy.html#the-basic-concept",
    "href": "diabetic-retinopathy.html#the-basic-concept",
    "title": "Diabetic Retinopathy Detection",
    "section": "The Basic Concept",
    "text": "The Basic Concept\nBroadly speaking, we’re turning data (the fundal image) into data (a number saying if DR is present or not). The fundal image is itself made out of pixels, which are numbers.\nHere is information about 1 pixel in a zoomed in fundal picture. \nThe values on the left (777 and 424) refer to the coordinates of the pixel. The values on the right refer to its “Red, Blue, Green” (RGB) values - how red, blue and green the pixel is out of a maximum of 255. Understandably, the fundus is more red than blue or green (181,95,48).\nThis is what it would look like if we split up the 3 colour channels. \nBut the main point is that an image is simply numbers! For simplicity’s sake, let’s assume there is just 1 channel.\nThis is the essence of the whole model.",
    "crumbs": [
      "Ophthalmology",
      "Diabetic Retinopathy Detection"
    ]
  },
  {
    "objectID": "diabetic-retinopathy.html#the-basic-math",
    "href": "diabetic-retinopathy.html#the-basic-math",
    "title": "Diabetic Retinopathy Detection",
    "section": "The Basic Math",
    "text": "The Basic Math\nWe’re going to use basic addition and multiplication to turn all these pixel numbers into a final number.\nThe first transformation we do is called a convolution (hence these models are called convolutional neural networks).\nYou start off with the image matrix and a kernal (a matrix of numbers) \nWe move a kernal along the image, multiplying each kernal’s value by the pixel value and adding all of them up. \nAfter we apply the kernal through the image, it gives us a new matrix that we call a feature map. \nNow, why is it called a feature map? A feature map maps out key features the model uses for classification. Let’s run the number 7 from the famous MNIST database through the kernal, a large database of handwritten digits. \nAs you can see, the our feature map has highlighted the vertical parts of the image. In a sense, the model has learned what vertical lines are! Let’s use another kernal and see what happens. \n\n\n\n\n\n\nTip\n\n\n\nUsing the multiplication and addition steps we explained above, try to see why those two kernals generate their respective feature maps!",
    "crumbs": [
      "Ophthalmology",
      "Diabetic Retinopathy Detection"
    ]
  },
  {
    "objectID": "diabetic-retinopathy.html#the-basic-model",
    "href": "diabetic-retinopathy.html#the-basic-model",
    "title": "Diabetic Retinopathy Detection",
    "section": "The Basic Model",
    "text": "The Basic Model\nIn an actual model, the original image is transformed by numerous different kernals to form a variety of feature maps. The feature maps themselves become the input to different kernals, forming new maps. This multi-layered (hence deep in ‘deep learning’) nature means complex combinations of features can be detected. The beauty of deep learning is that we don’t have to set kernals for what features we think are important - the model does that by itself. Let’s see how it does that.\n\n\n\n\n\n\nJargon\n\n\n\nThe secret behind machine learning (of which deep learning is a subset of) is “gradient descent.” We’ll describe its intuition here.\n\n\nSuppose I have a deep learning model that tells me if a number is 7 or not. One catch is that all of numbers in the kernals are randomised, meaning no meaningful features are being identified - our model doesn’t work. I draw the number 7 and test the model. It predicts 50-50 for if it is a 7 or not. But we know that the correct answer is 100-0 that it is a 7. Let’s say we want to improve our model so we randomly tweak the kernals. Now the model’s prediction is 60-40 in favour of 7. The model is improving!\nSimply put, I want to figure out what number the kernal needs to be for our model’s prediction to be the best. This is a calculus question. With basic calculus, you can derive the direction (increase or decrease) each kernal value needs to change to improve the prediction. Now, every time our model updates its kernal values, it is improving - it is learning!\nWe incrementally update the kernal values, recalculating the gradient at each step so we know which direction to move in. The rate at which we change the kernals is called the learning rate (more to come on this). \nVoilà - we are now training our model! In essence, we give the model the lot of practice questions (the data) and the answer sheet (the data’s interpretation) and tell it to figure it out. This is both intelligent and not so intelligent. What if it sees a unique fundus that it has not been trained to see? Perhaps the innate features it has gathered is sufficient to remain accurate but perhaps it is not. Perhaps the dataset it is trained on is biased towards a particular demographic. Perhaps you work with a specific demographic of people and the original dataset it was trained on is too different.\nThis means that the training data must be heretogenous so it can work for a wide range of real-life cases. This makes it important to be critical of the sensitivity/specificity described by papers showcasing the model. Depending on the dataset the model was tested on, it may not be applicable to your patient.\nYou must be aware that the sensitivity/specificity described is based on a test dataset researchers have used (it varies from dataset to dataset) and ensure it is directly applicable to your patient. Here is a table from Gargeya & Leng: .\nThe model still performs extremely well but there is variable performance across datasets and data types (‘mild vs severe’ DR).",
    "crumbs": [
      "Ophthalmology",
      "Diabetic Retinopathy Detection"
    ]
  }
]